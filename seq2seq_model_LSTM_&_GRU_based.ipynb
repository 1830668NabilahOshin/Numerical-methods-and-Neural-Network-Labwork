{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1830668NabilahOshin/Numerical-methods-and-Neural-Network-Labwork/blob/main/seq2seq_model_LSTM_%26_GRU_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "9pLLUiIyq6Py"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKCRyciQp0Rp",
        "outputId": "1498ff72-58d1-4508-a9ed-c77b7614ed19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading pretrained word2vec model"
      ],
      "metadata": {
        "id": "M6GOnIkGq_a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SENDBpHsqENY",
        "outputId": "b3766ac1-b2f9-4ccc-f415-8747c2227394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Preprocessor"
      ],
      "metadata": {
        "id": "Jo5Bnv6IrGAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.punctuations = set(string.punctuation)\n",
        "\n",
        "    def process_text(self, text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        text = re.sub(r'<.*?>', '', text)\n",
        "        text = ''.join(char for char in text if char not in self.punctuations)\n",
        "        tokens = word_tokenize(text)\n",
        "        tokens = [token for token in tokens if token not in self.stop_words]\n",
        "        text = ' '.join(tokens)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def process_column(self, df, column_name):\n",
        "        df[column_name] = df[column_name].apply(self.process_text)\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "B_4erx3SqIke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading dataset"
      ],
      "metadata": {
        "id": "sY1lnFgXrKvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "data = pd.read_csv('Clothes-Review.csv' , encoding='ISO-8859-1', header=0)\n",
        "\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35FAAGdQqMQ6",
        "outputId": "e89992a3-50d5-49e8-af3e-e4aafe5d230f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
            "0           0          767   33                      NaN   \n",
            "1           1         1080   34                      NaN   \n",
            "2           2         1077   60  Some major design flaws   \n",
            "3           3         1049   50         My favorite buy!   \n",
            "4           4          847   47         Flattering shirt   \n",
            "\n",
            "                                         Review Text  Rating  Recommended IND  \\\n",
            "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
            "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
            "2  I had such high hopes for this dress and reall...       3                0   \n",
            "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
            "4  This shirt is very flattering to all due to th...       5                1   \n",
            "\n",
            "   Positive Feedback Count   Division Name Department Name Class Name  \n",
            "0                        0       Initmates        Intimate  Intimates  \n",
            "1                        4         General         Dresses    Dresses  \n",
            "2                        0         General         Dresses    Dresses  \n",
            "3                        0  General Petite         Bottoms      Pants  \n",
            "4                        6         General            Tops    Blouses  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)\n",
        "data.columns = data.columns.str.strip()\n",
        "dataf = data[['Review Text', 'Recommended IND']]\n",
        "print(dataf.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp4Xd1CetfhJ",
        "outputId": "bf24f82e-7a0c-4c02-e04b-122c438b947c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'Clothing ID', 'Age', 'Title', 'Review Text', 'Rating',\n",
            "       'Recommended IND', 'Positive Feedback Count', 'Division Name',\n",
            "       'Department Name', 'Class Name'],\n",
            "      dtype='object')\n",
            "                                         Review Text  Recommended IND\n",
            "0  Absolutely wonderful - silky and sexy and comf...                1\n",
            "1  Love this dress!  it's sooo pretty.  i happene...                1\n",
            "2  I had such high hopes for this dress and reall...                0\n",
            "3  I love, love, love this jumpsuit. it's fun, fl...                1\n",
            "4  This shirt is very flattering to all due to th...                1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataf = data[['Review Text', 'Recommended IND']]\n",
        "print(dataf.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5w2ibiVo4OK",
        "outputId": "3a2c8f7f-024d-490e-ab54-b8db2ef2d758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Review Text  Recommended IND\n",
            "0  Absolutely wonderful - silky and sexy and comf...                1\n",
            "1  Love this dress!  it's sooo pretty.  i happene...                1\n",
            "2  I had such high hopes for this dress and reall...                0\n",
            "3  I love, love, love this jumpsuit. it's fun, fl...                1\n",
            "4  This shirt is very flattering to all due to th...                1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying preprocessor on Dataset"
      ],
      "metadata": {
        "id": "BktomVz1rOQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = TextPreprocessor()\n",
        "data['Review Text'] = data['Review Text'].fillna('')\n",
        "df = preprocessor.process_column(data, 'Review Text')\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NCTuFf2qPdi",
        "outputId": "37de1d78-9703-4789-f63f-7620d91ce93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
            "0           0          767   33                      NaN   \n",
            "1           1         1080   34                      NaN   \n",
            "2           2         1077   60  Some major design flaws   \n",
            "3           3         1049   50         My favorite buy!   \n",
            "4           4          847   47         Flattering shirt   \n",
            "\n",
            "                                         Review Text  Rating  Recommended IND  \\\n",
            "0        absolutely wonderful silky sexy comfortable       4                1   \n",
            "1  love dress sooo pretty happened find store im ...       5                1   \n",
            "2  high hopes dress really wanted work initially ...       3                0   \n",
            "3  love love love jumpsuit fun flirty fabulous ev...       5                1   \n",
            "4  shirt flattering due adjustable front tie perf...       5                1   \n",
            "\n",
            "   Positive Feedback Count   Division Name Department Name Class Name  \n",
            "0                        0       Initmates        Intimate  Intimates  \n",
            "1                        4         General         Dresses    Dresses  \n",
            "2                        0         General         Dresses    Dresses  \n",
            "3                        0  General Petite         Bottoms      Pants  \n",
            "4                        6         General            Tops    Blouses  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to get w2v vectors"
      ],
      "metadata": {
        "id": "9BM0XYNIrUEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v(sentence):\n",
        "    tokenized_data = sentence.split()\n",
        "    n_tokens = len(tokenized_data)\n",
        "    if n_tokens >= 10:\n",
        "        tokenized_data = tokenized_data[:10]\n",
        "    else:\n",
        "        pad_length = 10 - n_tokens\n",
        "        tokenized_data += [\"<EOS>\"] * pad_length\n",
        "\n",
        "    vectors = []\n",
        "    for token in tokenized_data:\n",
        "        if token in w2v_model:\n",
        "            vec = w2v_model[token]\n",
        "        else:\n",
        "            vec = np.zeros(w2v_model.vector_size)\n",
        "        vectors.append(vec)\n",
        "\n",
        "    tensor = torch.stack([torch.tensor(vec, dtype=torch.float32) for vec in vectors])\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "uNhYwIiNqTZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining Datasethelper child class"
      ],
      "metadata": {
        "id": "l8cQqFForbRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Datasethelper(Dataset):\n",
        "  def __init__(self, df):\n",
        "    super().__init__()\n",
        "    self.data = df['Review Text'].values\n",
        "    self.labels = df['Recommended IND'].values\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    text = self.data[index]\n",
        "    label = self.labels[index]\n",
        "    w2v_data = w2v(text)\n",
        "    label = torch.tensor( label , dtype=torch.float32)\n",
        "    #print(w2v_data.shape)\n",
        "    #print(w2v_data.dtype)\n",
        "    return w2v_data, label"
      ],
      "metadata": {
        "id": "V4-0DxyFqWxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting dataset + Preparing dataset by Dataloader"
      ],
      "metadata": {
        "id": "qWY4BpMPrfGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_helper = Datasethelper(train_df)\n",
        "test_helper = Datasethelper(test_df)\n",
        "\n",
        "\n",
        "train_dloader = DataLoader(train_helper, batch_size = 12 , shuffle = True)\n",
        "test_dloader = DataLoader(test_helper, batch_size = 12 , shuffle = False)"
      ],
      "metadata": {
        "id": "LA3AxaojqaKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking shapes"
      ],
      "metadata": {
        "id": "zdWKrPmarl9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_dloader:\n",
        "  break\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYe7pNMPqgYZ",
        "outputId": "6cb7e5d1-e31b-4210-ccc4-02e28952c236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12, 10, 300])\n",
            "torch.Size([12])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "========================================================  shuru"
      ],
      "metadata": {
        "id": "I7Xd5MHZCaoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM based seq2seq Model"
      ],
      "metadata": {
        "id": "4RFl3F6kxyMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Seq2SeqLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.encoder = nn.LSTM(input_size, hidden_size)\n",
        "        self.decoder = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_output, (encoder_hidden, encoder_cell) = self.encoder(x)\n",
        "        decoder_output, _ = self.decoder(encoder_output, (encoder_hidden, encoder_cell))\n",
        "        output = self.fc(decoder_output)\n",
        "        output = output[:, 0, :]\n",
        "        return output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NA6tBt04CfjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initating before training"
      ],
      "metadata": {
        "id": "SHy_6uMRx2nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_size = 300\n",
        "hidden_size = 128\n",
        "output_size = 1\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Seq2SeqLSTM(input_size, hidden_size, output_size)\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "XBPn-O9HCmDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "2xlSQ-L0x6nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_dloader)\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_correct = 0\n",
        "    epoch_total = 0\n",
        "    for i, (x, y) in enumerate(train_dloader):\n",
        "        model.train()\n",
        "\n",
        "\n",
        "        outputs = model(x)\n",
        "        #print(outputs.shape)\n",
        "        outputs = outputs.squeeze()\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        predicted_labels = torch.round(torch.sigmoid(outputs))\n",
        "        correct = (predicted_labels == y).sum().item()\n",
        "        total = y.size(0)\n",
        "        accuracy = correct / total\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_correct += correct\n",
        "        epoch_total += total\n",
        "\n",
        "    epoch_loss /= total_step\n",
        "    epoch_accuracy = epoch_correct / epoch_total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhpUKghaxGHd",
        "outputId": "f1cdac5b-e1c7-4b93-edb8-7365cc1fbfa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4062, Accuracy: 0.8384\n",
            "Epoch [2/10], Loss: 0.4041, Accuracy: 0.8390\n",
            "Epoch [3/10], Loss: 0.4029, Accuracy: 0.8397\n",
            "Epoch [4/10], Loss: 0.4006, Accuracy: 0.8396\n",
            "Epoch [5/10], Loss: 0.3990, Accuracy: 0.8415\n",
            "Epoch [6/10], Loss: 0.3978, Accuracy: 0.8415\n",
            "Epoch [7/10], Loss: 0.3963, Accuracy: 0.8429\n",
            "Epoch [8/10], Loss: 0.3954, Accuracy: 0.8415\n",
            "Epoch [9/10], Loss: 0.3942, Accuracy: 0.8423\n",
            "Epoch [10/10], Loss: 0.3937, Accuracy: 0.8426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "-WmxBq4Tx9o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in test_dloader:\n",
        "        outputs = model(x)\n",
        "        outputs = outputs.squeeze()\n",
        "        predicted = torch.round(torch.sigmoid(outputs))\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esqOZekUC5Zz",
        "outputId": "139bdf72-25b9-41ed-b617-68d1acfa0693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU based seq2seq Model"
      ],
      "metadata": {
        "id": "mG7bg3b0Cdg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Seq2SeqGRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.encoder = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder = nn.GRU(hidden_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_output, encoder_hidden = self.encoder(x)\n",
        "        decoder_output, _ = self.decoder(encoder_output, encoder_hidden)\n",
        "        output = self.fc(decoder_output)\n",
        "        output = output[:, 0, :]  # Select the first element along the second dimension\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "DpjQu4sqy3S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters\n",
        "input_size1 = 300\n",
        "hidden_size1 = 128\n",
        "output_size1 = 1\n",
        "num_epochs1 = 10\n",
        "learning_rate1 = 0.001\n",
        "\n",
        "# Initialize the model\n",
        "model1 = Seq2SeqGRU(input_size1, hidden_size1, output_size1)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion1 = nn.BCEWithLogitsLoss()\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "sesqqpLCy8oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_dloader)\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_correct = 0\n",
        "    epoch_total = 0\n",
        "    for i, (x, y) in enumerate(train_dloader):\n",
        "        model1.train()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model1(x)\n",
        "        outputs = outputs.squeeze()\n",
        "        loss = criterion1(outputs, y)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer1.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        predicted_labels = torch.round(torch.sigmoid(outputs))\n",
        "        correct = (predicted_labels == y).sum().item()\n",
        "        total = y.size(0)\n",
        "        accuracy = correct / total\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_correct += correct\n",
        "        epoch_total += total\n",
        "\n",
        "    epoch_loss /= total_step\n",
        "    epoch_accuracy = epoch_correct / epoch_total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDmTMefuzPG2",
        "outputId": "8669dc91-74ff-45c5-e352-b7f855807abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4506, Accuracy: 0.8255\n",
            "Epoch [2/10], Loss: 0.4349, Accuracy: 0.8287\n",
            "Epoch [3/10], Loss: 0.4309, Accuracy: 0.8316\n",
            "Epoch [4/10], Loss: 0.4280, Accuracy: 0.8312\n",
            "Epoch [5/10], Loss: 0.4253, Accuracy: 0.8322\n",
            "Epoch [6/10], Loss: 0.4233, Accuracy: 0.8338\n",
            "Epoch [7/10], Loss: 0.4222, Accuracy: 0.8340\n",
            "Epoch [8/10], Loss: 0.4200, Accuracy: 0.8348\n",
            "Epoch [9/10], Loss: 0.4190, Accuracy: 0.8351\n",
            "Epoch [10/10], Loss: 0.4175, Accuracy: 0.8355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "model1.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in test_dloader:\n",
        "        outputs = model1(x)\n",
        "        outputs = outputs.squeeze()\n",
        "        predicted = torch.round(torch.sigmoid(outputs))\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I4Ln4MPzt7Q",
        "outputId": "8ff68a9a-13b2-4b83-acbd-e8718182fd0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#seq2seq with attention"
      ],
      "metadata": {
        "id": "sLaIDMjW5LcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Seq2SeqAttention(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Seq2SeqAttention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.encoder = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder = nn.GRU(hidden_size + input_size, hidden_size)  # Concatenate input with attention context\n",
        "        self.attention = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_output, encoder_hidden = self.encoder(x)\n",
        "\n",
        "        decoder_hidden = encoder_hidden  # Initialize decoder hidden state with encoder final hidden state\n",
        "\n",
        "        outputs = []\n",
        "        for i in range(x.size(0)):\n",
        "            context = self.attention(decoder_hidden[-1])  # Calculate attention context\n",
        "            context = context.unsqueeze(0).expand_as(encoder_output)  # Expand context to match encoder output size\n",
        "\n",
        "            attended_encoder_output = encoder_output * F.softmax(context, dim=2)  # Apply attention weights\n",
        "            attended_encoder_output = torch.sum(attended_encoder_output, dim=0)  # Sum the attended encoder output\n",
        "\n",
        "            decoder_input = torch.cat((x[i].unsqueeze(0), attended_encoder_output.unsqueeze(0)), dim=2)  # Concatenate input with attention context\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "            output = self.fc(decoder_output)\n",
        "            outputs.append(output)\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=0)\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "FLcf4YzB1cGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}